{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c6e116",
   "metadata": {},
   "source": [
    "# FreeYourHandv2.1.2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ae409",
   "metadata": {},
   "source": [
    "v2.1：\n",
    "\n",
    "- 加入了对```HTTP500```问题的处理\n",
    "\n",
    "v2.1.1:\n",
    "\n",
    "- 修复了合并后缺失文件的问题\n",
    "\n",
    "v2.1.2:\n",
    "\n",
    "- 加入了对偶尔下载弹窗未弹出的处理\n",
    "\n",
    "- 修复了下一页未成功加载时卡刷新的问题\n",
    "\n",
    "- 开始时增加了当前时间范围的输出方便报错时确认时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b1ef1b",
   "metadata": {},
   "source": [
    "## 导入库\n",
    "直接运行就好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04742704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f9be48",
   "metadata": {},
   "source": [
    "# ！！！设置参数\n",
    "\n",
    "---\n",
    "\n",
    "这部分是全部的参数设置，大部分是设置好了的，但仍有几个路径需要你自己调整。\n",
    "\n",
    "**请写好参数后再运行**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "654f5d8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting driver......\n"
     ]
    }
   ],
   "source": [
    "# 点击按钮的睡眠时间,2即可，会在出现按钮后等待2秒，点击，再等待两秒。\n",
    "button_sleep_time = 2\n",
    "\n",
    "# 是否是中文网页，如果是，那么输入True,不是则False。\n",
    "isChinese = False\n",
    "\n",
    "# 浏览器用的哪一个就留哪一个并去掉前面的#，然后把另外的都删掉！！或者前面加个#注释掉，弹出的浏览器不要关\n",
    "driver = webdriver.Firefox()\n",
    "\n",
    "# Initialization....\n",
    "print('Starting driver......')\n",
    "driver.get('http://www.99885.net')\n",
    "\n",
    "# setting up waitting time\n",
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410428a1",
   "metadata": {},
   "source": [
    "## 定义将要使用的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21fffa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "def get_page_soup():\n",
    "    '''\n",
    "    get page source and turn into Beautiful soup.\n",
    "    '''\n",
    "    return bs(driver.page_source, 'html.parser')\n",
    "\n",
    "\n",
    "def is_more_pages():\n",
    "    '''\n",
    "    test for if there is next page.\n",
    "    '''\n",
    "    li = get_page_soup()\n",
    "    li_class = li.select_one('.pagination > li:nth-last-child(2)').get('class')\n",
    "    \n",
    "    return (li_class == None)\n",
    "\n",
    "def click_button(CSS_Selector):\n",
    "    '''\n",
    "    click a button by its CSS_Slector.\n",
    "    '''\n",
    "    global button_sleep_time\n",
    "    wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, CSS_Selector)))\n",
    "    sleep(button_sleep_time)\n",
    "    button = driver.find_element(By.CSS_SELECTOR, CSS_Selector)\n",
    "    button.click()\n",
    "    # waitting time after click button\n",
    "    sleep(button_sleep_time)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def download_files():\n",
    "    '''\n",
    "    Downloading file after selection.\n",
    "    '''\n",
    "    global isChinese\n",
    "    \n",
    "    if isChinese:\n",
    "        request_complete = '请求完成'\n",
    "    else:\n",
    "        request_complete = 'Request complete'\n",
    "        \n",
    "    not_start_downloading = True\n",
    "    counter = 0\n",
    "    failed = False\n",
    "    \n",
    "    while not_start_downloading:    \n",
    "        try:\n",
    "            # click (...) button\n",
    "            click_button('.uxf-dot-three')\n",
    "\n",
    "            # click Text_only button\n",
    "            click_button('div.row-flex:nth-child(6) > div:nth-child(5) > a:nth-child(1) > span:nth-child(1) > span:nth-child(1)')\n",
    "            \n",
    "            if failed:\n",
    "                sleep(5)\n",
    "            # click Deselect items when done\n",
    "            click_button(\"[id^='deselectCheckBox_']\")\n",
    "\n",
    "            # click continue\n",
    "            click_button(\"[id^='submitButton_']\")\n",
    "            \n",
    "            not_start_downloading = False\n",
    "        except:\n",
    "            if counter >= 3:\n",
    "                print('You may excess your limit, please restart.')\n",
    "                raise Exception(\"You may excess you limit......\")\n",
    "            print('Dowdloading cell not appearing, refresh page now.')\n",
    "            driver.refresh()\n",
    "            sleep(5)\n",
    "            failed = True\n",
    "            counter += 1\n",
    "    sleep(10)\n",
    "    \n",
    "    # siwtch to downloading page\n",
    "    driver.switch_to.window(driver.window_handles[-1])\n",
    "    not_finished = (get_page_soup().select_one('.header_border_bottom > h1:nth-child(1)').text) != request_complete\n",
    "    waiting_time = 0\n",
    "    \n",
    "    while not_finished:\n",
    "        sleep(10)\n",
    "        waiting_time += 10\n",
    "        not_finished = (get_page_soup().select_one('.header_border_bottom > h1:nth-child(1)').text) != request_complete\n",
    "        if waiting_time >= 150:\n",
    "            print(\"Waiting exceed 150, \\033[1;32mRefresh\\033[0m page...\")\n",
    "            driver.refresh()\n",
    "            waiting_time = 0\n",
    "            sleep(5)\n",
    "        \n",
    "    print('\\033[1;32mRequest complete!\\033[0m')\n",
    "    sleep(3)\n",
    "    # close the downloading tab and switch back.\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[-1])\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_current_page_num():\n",
    "    '''\n",
    "    get current page number.\n",
    "    '''\n",
    "    page = get_page_soup()\n",
    "    \n",
    "    return int(page.select('#pageNbrField')[0].get('value'))\n",
    "\n",
    "\n",
    "def input_num(num, CSS_Selector):\n",
    "    '''\n",
    "    input a number to the box\n",
    "    '''\n",
    "    box = driver.find_element(By.CSS_SELECTOR, CSS_Selector)\n",
    "    box.clear()\n",
    "    box.send_keys(num)\n",
    "    box.send_keys(Keys.RETURN)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def read_html_to_soup(file_path):\n",
    "    '''\n",
    "    read a html file into soup.\n",
    "    '''\n",
    "    with open(file_path, 'r') as file:\n",
    "        html_content = file.read()\n",
    "        \n",
    "    soup = bs(html_content, 'html.parser')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406ff0d2",
   "metadata": {},
   "source": [
    "## 开始下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0505b59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scraper Working now......\n",
      "Time Range :  1931-12-01 - 1931-12-31\n",
      "========================================\n",
      "------Now in page \u001b[1;32m36\u001b[0m------\n",
      "Page 36 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m37\u001b[0m------\n",
      "Page 37 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m38\u001b[0m------\n",
      "Page 38 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m39\u001b[0m------\n",
      "Page 39 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m40\u001b[0m------\n",
      "Page 40 Selected\n",
      "\u001b[1;32mStart downloading page 36-40\u001b[0m\n",
      "\u001b[1;32mRequest complete!\u001b[0m\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m41\u001b[0m------\n",
      "Page 41 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m42\u001b[0m------\n",
      "Page 42 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m43\u001b[0m------\n",
      "Page 43 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m44\u001b[0m------\n",
      "Page 44 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m45\u001b[0m------\n",
      "Page 45 Selected\n",
      "\u001b[1;32mStart downloading page 41-45\u001b[0m\n",
      "\u001b[1;32mRequest complete!\u001b[0m\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m46\u001b[0m------\n",
      "Page 46 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m47\u001b[0m------\n",
      "Page 47 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m48\u001b[0m------\n",
      "Page 48 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m49\u001b[0m------\n",
      "Page 49 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m50\u001b[0m------\n",
      "Page 50 Selected\n",
      "\u001b[1;32mStart downloading page 46-50\u001b[0m\n",
      "\u001b[1;32mRequest complete!\u001b[0m\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m51\u001b[0m------\n",
      "Page 51 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m52\u001b[0m------\n",
      "Page 52 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m53\u001b[0m------\n",
      "Page 53 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m54\u001b[0m------\n",
      "Page 54 Selected\n",
      "Click next page.\n",
      "------Now in page \u001b[1;32m55\u001b[0m------\n",
      "Page 55 Selected\n",
      "\u001b[1;32mStart downloading page 51-55\u001b[0m\n",
      "\u001b[1;32mRequest complete!\u001b[0m\n",
      "Click next page.\n",
      "Selecting last page.\n",
      "Start downloading page 56-56\n",
      "\u001b[1;32mRequest complete!\u001b[0m\n",
      "\n",
      "\u001b[1;32mAll Task Finished!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# switch to right-most tab\n",
    "driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "# setting up parameters\n",
    "selected_pages = 0\n",
    "\n",
    "# downloading....\n",
    "print('========================================')\n",
    "print('Scraper Working now......')\n",
    "print('Time Range : ', get_page_soup().select_one('#dateFilter-div > ul:nth-child(1) > li:nth-child(1) > div:nth-child(2) > span:nth-child(1)').get_text())\n",
    "print('========================================')\n",
    "while is_more_pages():\n",
    "    current_page = get_current_page_num()\n",
    "    print(f'------Now in page \\033[1;32m{current_page}\\033[0m------')\n",
    "    # click \"select\"\n",
    "    click_button('#mlcbAll')\n",
    "    selected_pages += 1\n",
    "    print(f'Page {current_page} Selected')\n",
    "    \n",
    "    # start downloading if selected 5 pages\n",
    "    if selected_pages == 5:\n",
    "        print(f'\\033[1;32mStart downloading page {current_page - 4}-{current_page}\\033[0m')\n",
    "        download_files()\n",
    "        selected_pages = 0\n",
    "    \n",
    "    # turn to next page\n",
    "    print('Click next page.')\n",
    "    click_button('.uxf-right-open-large')\n",
    "    \n",
    "    \n",
    "    # test for if the next page is loaded.\n",
    "    total_waiting_time = 0\n",
    "    not_next_page = True\n",
    "    \n",
    "    while not_next_page:\n",
    "        sleep(3)\n",
    "        total_waiting_time += 3\n",
    "        \n",
    "        try:\n",
    "            if current_page == get_current_page_num() - 1:\n",
    "                not_next_page = False\n",
    "        except:\n",
    "            h1 = get_page_soup().select_one('body > h1').get_text()\n",
    "            if h1 == 'HTTP Status 500 – Internal Server Error':\n",
    "                print(f'\\033[1;31mHTTP Status 500 Error\\033[0m encounterd while trying turn to page {current_page + 1}')\n",
    "                print('Refresh page...')\n",
    "                driver.refresh()\n",
    "                sleep(3)\n",
    "            \n",
    "        if (total_waiting_time > 29) and not_next_page:\n",
    "            print('Waiting more than 30s for next page, \\033[1;31mrefresh page\\033[0m now.')\n",
    "            driver.refresh()\n",
    "            sleep(3)\n",
    "            wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, '#pageNbrField')))\n",
    "            input_num(current_page + 1, '#pageNbrField')\n",
    "            total_waiting_time = 0\n",
    "            \n",
    "\n",
    "# downloading last page\n",
    "print('Selecting last page.')\n",
    "click_button('#mlcbAll')\n",
    "selected_pages += 1\n",
    "print(f'Start downloading page {current_page + 1}-{get_current_page_num()}')\n",
    "download_files()\n",
    "print('\\n\\033[1;32mAll Task Finished!\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46258722",
   "metadata": {},
   "source": [
    "## 结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d06d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quit the driver.\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a329266",
   "metadata": {},
   "source": [
    "# 文件合并与排序\n",
    "\n",
    "---\n",
    "\n",
    "该jupyter notebook 用于下载完成后的合并与排序。\n",
    "\n",
    "代码其实是Chatgpt4帮我写的，不过这部分代码只需要基础的python库所以应该都没问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd809795",
   "metadata": {},
   "source": [
    "## 设置文件路径\n",
    "\n",
    "第一步是新建一个文件夹，把所有下载的文件放进去。\n",
    "\n",
    "然后我推荐你复制进去留个备份而不是剪切进去防止代码有问题全丢了白干。\n",
    "\n",
    "第二步，记住这个文件夹的绝对路径。比如，你把所有文件放在了D盘的merge文件夹，\n",
    "\n",
    "然后你就应该在下面的```\"\"```里面填入```D:\\\\merge\\```\n",
    "\n",
    "我不确定我这路径里斜线写的对不对，更方便的，你先输入```D:```，然后按一下```tab```，应该就会出现D盘的路径了，再按一下，就会出现D盘下的所有文件了，选择merge/就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14857a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里是我自己的路径，我放到了nolan用户下的downloads文件下的111文件夹里面。你删掉\"\"里面的就行，可别把“”删了。\n",
    "# 注意一定是英文输入法\n",
    "directory = \"/home/nolan/Downloads/111/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e96d927",
   "metadata": {},
   "source": [
    "接下来直接运行就行了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc13fa69",
   "metadata": {},
   "source": [
    "## 去除每个文件最后的版权内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d5eace4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;32mAll Task Finished!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def remove_last_section_if_url_present(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.readlines()\n",
    "\n",
    "    separator = \"____________________________________________________________\\n\"\n",
    "    url_text = \"http://about.proquest.com/go/pqissupportcontact\"\n",
    "    if separator in content:\n",
    "        last_separator_index = len(content) - 1 - content[::-1].index(separator)\n",
    "        last_section = content[last_separator_index:]\n",
    "\n",
    "        if any(url_text in line for line in last_section):\n",
    "            content = content[:last_separator_index]\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(content)\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            remove_last_section_if_url_present(file_path)\n",
    "\n",
    "process_folder(directory)\n",
    "print('\\n\\033[1;32mAll Task Finished!\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673dfc1c",
   "metadata": {},
   "source": [
    "## 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "440e9006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;32mAll Task Finished!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def extract_date(text):\n",
    "    if isChinese:\n",
    "        match = re.search(r'出版日期: (\\w+ \\d{1,2}, \\d{4})', text)\n",
    "    else:\n",
    "        match = re.search(r'Publication date: (\\w+ \\d{1,2}, \\d{4})', text)\n",
    "    if match:\n",
    "        date_str = match.group(1)\n",
    "        # 将日期字符串转换为 datetime 对象，然后格式化为 YYYYMM\n",
    "        return datetime.strptime(date_str, '%b %d, %Y').strftime('%Y%m')\n",
    "    return None\n",
    "\n",
    "def merge_files(folder_path):\n",
    "    files_data = {}  # 用于存储年月和对应的文件内容\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                date = extract_date(content)\n",
    "\n",
    "                if date:\n",
    "                    if date in files_data:\n",
    "                        files_data[date].append(content)\n",
    "                    else:\n",
    "                        files_data[date] = [content]\n",
    "\n",
    "    for date, contents in files_data.items():\n",
    "        merged_filename = f\"{date}.txt\"\n",
    "        with open(os.path.join(folder_path, merged_filename), 'w', encoding='utf-8') as merged_file:\n",
    "            merged_file.write('\\n____________________________________________________________\\n'.join(contents))\n",
    "\n",
    "            \n",
    "def delete_specific_files(directory, keyword):\n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the keyword is in the filename\n",
    "            if keyword in file and file.endswith('.txt'):\n",
    "                # Construct the full file path\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Delete the file\n",
    "                os.remove(file_path)\n",
    "\n",
    "merge_files(directory)\n",
    "delete_specific_files(directory, 'ProQuestDocuments')\n",
    "print('\\n\\033[1;32mAll Task Finished!\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb2166",
   "metadata": {},
   "source": [
    "## 排序\n",
    "\n",
    "---\n",
    "\n",
    "下面的代码进行排序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50a484fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;32mAll Task Finished!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def parse_date(article):\n",
    "    date_match = re.search(r'Publication date: (\\w+ \\d+, \\d+)', article)\n",
    "    if date_match:\n",
    "        date_str = date_match.group(1)\n",
    "        try:\n",
    "            return datetime.strptime(date_str, '%b %d, %Y')\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def sort_articles_by_date(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    articles = content.split('____________________________________________________________')\n",
    "\n",
    "    # Filter out articles without a valid date\n",
    "    articles_with_date = [article for article in articles if parse_date(article) is not None]\n",
    "    articles_without_date = [article for article in articles if parse_date(article) is None]\n",
    "\n",
    "    sorted_articles = sorted(articles_with_date, key=parse_date)\n",
    "\n",
    "    # Append the articles without a date to the end\n",
    "    sorted_articles.extend(articles_without_date)\n",
    "\n",
    "    return sorted_articles\n",
    "\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        sorted_articles = sort_articles_by_date(file_path)\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write('____________________________________________________________'.join(sorted_articles))\n",
    "            \n",
    "            \n",
    "print('\\n\\033[1;32mAll Task Finished!\\033[0m')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
